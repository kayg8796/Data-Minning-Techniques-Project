{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('train2.csv')\n",
    "testset = pd.read_csv('test_without_labels2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= dataset.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "What is the step by step guide to invest in share market?\n",
      "\n",
      "What is the story of Kohinoor (Koh-i-Noor) Diamond?\n",
      "What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\n",
      "\n",
      "How can I increase the speed of my internet connection while using a VPN?\n",
      "How can Internet speed be increased by hacking through DNS?\n",
      "\n",
      "Why am I mentally very lonely? How can I solve it?\n",
      "Find the remainder when [math]23^{24}[/math] is divided by 24,23?\n",
      "\n",
      "Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?\n",
      "Which fish would survive in salt water?\n",
      "\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "\n",
      "Should I buy tiago?\n",
      "What keeps childern active and far from phone and video games?\n",
      "\n",
      "How can I be a good geologist?\n",
      "What should I do to be a great geologist?\n",
      "\n",
      "When do you use シ instead of し?\n",
      "When do you use \"&\" instead of \"and\"?\n",
      "\n",
      "Motorola (company): Can I hack my Charter Motorolla DCX3400?\n",
      "How do I hack Motorola DCX3400 for free internet?\n",
      "\n",
      "Method to find separation of slits using fresnel biprism?\n",
      "What are some of the things technicians can tell about the durability and reliability of Laptops and its components?\n",
      "\n",
      "How do I read and find my YouTube comments?\n",
      "How can I see all my Youtube comments?\n",
      "\n",
      "What can make Physics easy to learn?\n",
      "How can you make physics easy to learn?\n",
      "\n",
      "What was your first sexual experience like?\n",
      "What was your first sexual experience?\n",
      "\n",
      "What are the laws to change your status from a student visa to a green card in the US, how do they compare to the immigration laws in Canada?\n",
      "What are the laws to change your status from a student visa to a green card in the US? How do they compare to the immigration laws in Japan?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print(dataset.Question1[i])\n",
    "    print(dataset.Question2[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, stem_words=True):\n",
    "    import re\n",
    "    from string import punctuation\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "    if type(text) != str or text=='':\n",
    "        return ''\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(\"\\'s\", \" \", text) \n",
    "    text = re.sub(\" whats \", \" what is \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(\"can't\", \"can not\", text)\n",
    "    text = re.sub(\"n't\", \" not \", text)\n",
    "    text = re.sub(\"i'm\", \"i am\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\'re\", \" are \", text)\n",
    "    text = re.sub(\"\\'d\", \" would \", text)\n",
    "    text = re.sub(\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(\"e\\.g\\.\", \" eg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"b\\.g\\.\", \" bg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"e-mail\", \" email \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.\", \" America \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?United State(s)?\", \" America \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(\"\\(s\\)\", \" \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(\"[c-fC-F]\\:\\/\", \" disk \", text) \n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text) #remove comma bn numbers\n",
    "    text = re.sub('\\$', \" dollar \", text)\n",
    "    text = re.sub('\\%', \" percent \", text)\n",
    "    text = re.sub('\\&', \" and \", text)\n",
    "    text = re.sub('[^\\x00-\\x7F]+', ' non_ascii_word ', text) \n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text, flags=re.IGNORECASE) #rs is indian dollar\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text, flags=re.IGNORECASE)  \n",
    "    \n",
    "    # some more clean text rules suggested online\n",
    "    text = re.sub(r\" UK \", \" England \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" imrovement \", \" improvement \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" intially \", \" initially \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" dms \", \" direct messages \", text, flags=re.IGNORECASE)  \n",
    "    text = re.sub(r\" demonitization \", \" demonetization \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(r\" actived \", \" active \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" kms \", \" kilometers \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(r\" upvote\", \" up vote\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" iPhone \", \" phone \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" \\0rs \", \" rs \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" calender \", \" calendar \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" ios \", \" operating system \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" gps \", \" GPS \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" gst \", \" GST \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" programing \", \" programming \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" bestfriend \", \" best friend \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" III \", \" 3 \", text)\n",
    "    text = re.sub(r\" J K \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub('[0-9]+\\.[0-9]+', \" 87 \", text) #random number that is replaced below\n",
    "    text = re.sub('[0-9]','number',text)\n",
    "    text = ''.join([c for c in text if c not in punctuation]).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['question1'] = dataset['Question1'].apply(clean)\n",
    "df['question2'] = dataset['Question2'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test set\n",
    "dft = pd.DataFrame()\n",
    "dft['question1'] = testset['Question1'].apply(clean)\n",
    "dft['question2'] = testset['Question2'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'[a-zA-Z_]{1,}', ngram_range=(2,3), max_features=5000)\n",
    "vectorizer.fit(pd.concat((df['question1'],df['question2'])))\n",
    "\n",
    "xt1 = vectorizer.transform(df['question1'].values)\n",
    "xt2 = vectorizer.transform(df['question2'].values)\n",
    "df1 = scipy.sparse.hstack((xt1,xt2))\n",
    "\n",
    "xtt1 = vectorizer.transform(dft['question1'].values)\n",
    "xtt2 = vectorizer.transform(dft['question2'].values)\n",
    "dftest = scipy.sparse.hstack((xtt1,xtt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report as clrp\n",
    "kf = KFold(n_splits=5)\n",
    "from xgboost import XGBClassifier\n",
    "classifier2 = XGBClassifier(max_depth=50, n_estimators=80, colsample_bytree=0.7, alpha=4, objective='binary:logistic', verbose=1, subsample=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import TruncatedSVD\n",
    "#svd = TruncatedSVD(n_components = 100,random_state=42)\n",
    "#svd.fit(scipy.sparse.vstack((df1,dftest)))\n",
    "#trainx = svd.transform(df1)\n",
    "#testx = svd.transform(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283004, 600)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier2.fit(df1,dataset.IsDuplicate)\n",
    "df2=df1.todense()#for use in cross validation\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283004,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = np.array(dataset.IsDuplicate)\n",
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86     35456\n",
      "           1       0.81      0.63      0.71     21145\n",
      "\n",
      "    accuracy                           0.81     56601\n",
      "   macro avg       0.81      0.77      0.78     56601\n",
      "weighted avg       0.81      0.81      0.80     56601\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86     35675\n",
      "           1       0.80      0.64      0.71     20926\n",
      "\n",
      "    accuracy                           0.81     56601\n",
      "   macro avg       0.81      0.77      0.79     56601\n",
      "weighted avg       0.81      0.81      0.80     56601\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86     35431\n",
      "           1       0.81      0.64      0.71     21170\n",
      "\n",
      "    accuracy                           0.81     56601\n",
      "   macro avg       0.81      0.77      0.78     56601\n",
      "weighted avg       0.81      0.81      0.80     56601\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.85     35587\n",
      "           1       0.80      0.63      0.71     21014\n",
      "\n",
      "    accuracy                           0.81     56601\n",
      "   macro avg       0.80      0.77      0.78     56601\n",
      "weighted avg       0.81      0.81      0.80     56601\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86     35732\n",
      "           1       0.81      0.64      0.72     20868\n",
      "\n",
      "    accuracy                           0.81     56600\n",
      "   macro avg       0.81      0.78      0.79     56600\n",
      "weighted avg       0.81      0.81      0.81     56600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(df2,tt):\n",
    "    classifier2.fit(df2[train_index],tt[train_index])\n",
    "    ypred=classifier2.predict(df2[test_index])\n",
    "    ytestt=tt[test_index]\n",
    "    print(clrp(ytestt,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2.fit(df1,tt)\n",
    "ypred = classifier2.predict(dftest)\n",
    "naive = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive['Id'] = testset['Id']\n",
    "naive['Predicted'] = ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive.to_csv('naive2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
