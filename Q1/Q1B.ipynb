{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report as clrp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "dataset = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227464</td>\n",
       "      <td>Netflix is coming to cable boxes, and Amazon i...</td>\n",
       "      <td>if you subscribe to one of three rinky-dink (...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244074</td>\n",
       "      <td>Pharrell, Iranian President React to Tehran 'H...</td>\n",
       "      <td>pharrell, iranian president react to tehran '...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60707</td>\n",
       "      <td>Wildlife service seeks comments</td>\n",
       "      <td>the u.s. fish and wildlife service has reopen...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27883</td>\n",
       "      <td>Facebook teams up with Storyful to launch 'FB ...</td>\n",
       "      <td>the very nature of social media means it is o...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169596</td>\n",
       "      <td>Caesars plans US$880 mln New York casino</td>\n",
       "      <td>caesars plans us$880 mln new york casino jul ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              Title  \\\n",
       "0  227464  Netflix is coming to cable boxes, and Amazon i...   \n",
       "1  244074  Pharrell, Iranian President React to Tehran 'H...   \n",
       "2   60707                    Wildlife service seeks comments   \n",
       "3   27883  Facebook teams up with Storyful to launch 'FB ...   \n",
       "4  169596           Caesars plans US$880 mln New York casino   \n",
       "\n",
       "                                             Content          Label  \n",
       "0   if you subscribe to one of three rinky-dink (...  Entertainment  \n",
       "1   pharrell, iranian president react to tehran '...  Entertainment  \n",
       "2   the u.s. fish and wildlife service has reopen...     Technology  \n",
       "3   the very nature of social media means it is o...     Technology  \n",
       "4   caesars plans us$880 mln new york casino jul ...       Business  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing 5 rows of dataset\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = dataset['Title']+dataset['Content']\n",
    "ytrain = dataset['Label']\n",
    "article=xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT CLEANING \n",
    "\n",
    "To clean the text, the following steps are implemented:\n",
    "\n",
    "- removing special characters and numbers\n",
    "- changing all letters to lower cases\n",
    "- removing stopwords\n",
    "- lematization \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "stop = stopwords.words('english3')\n",
    "\n",
    "def lemmatize_text1(text):\n",
    "    return [lemmatizer.lemmatize(w,pos=\"v\") for w in w_tokenizer.tokenize(text)]\n",
    "def lemmatize_text2(text):\n",
    "    return [lemmatizer.lemmatize(w,pos=\"n\") for w in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article= article.str.replace('[^\\w\\s]','') #remove punctuation\n",
    "article= article.str.replace('\\d+', '') #remove numbers \n",
    "article= article.apply(lambda x: \" \".join(x.lower() for x in x.split())) #lowercase\n",
    "article= article.apply(lemmatize_text1)\n",
    "article= article.apply(lemmatize_text2)\n",
    "article= article.apply(lambda x: \" \".join(x for x in x if x not in stop)) #remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "ytrain_matrix=labelencoder.fit_transform(ytrain)\n",
    "np.unique(ytrain_matrix)\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 10000) #the number of words to be included in the sparse matrix can be mordified \n",
    "xtrain_matrix = cv.fit_transform(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      4995\n",
      "           1       0.96      0.98      0.97      8947\n",
      "           2       0.97      0.91      0.94      2358\n",
      "           3       0.93      0.93      0.93      6059\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     22359\n",
      "   macro avg       0.94      0.93      0.94     22359\n",
      "weighted avg       0.94      0.94      0.94     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      5029\n",
      "           1       0.96      0.98      0.97      8878\n",
      "           2       0.96      0.91      0.93      2419\n",
      "           3       0.93      0.93      0.93      6033\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     22359\n",
      "   macro avg       0.94      0.93      0.94     22359\n",
      "weighted avg       0.94      0.94      0.94     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91      4893\n",
      "           1       0.96      0.97      0.97      8972\n",
      "           2       0.96      0.93      0.94      2442\n",
      "           3       0.93      0.92      0.93      6052\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     22359\n",
      "   macro avg       0.94      0.93      0.94     22359\n",
      "weighted avg       0.94      0.94      0.94     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      4889\n",
      "           1       0.96      0.98      0.97      9120\n",
      "           2       0.97      0.91      0.93      2351\n",
      "           3       0.93      0.93      0.93      5999\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     22359\n",
      "   macro avg       0.94      0.93      0.94     22359\n",
      "weighted avg       0.94      0.94      0.94     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      5028\n",
      "           1       0.96      0.98      0.97      8917\n",
      "           2       0.97      0.91      0.94      2450\n",
      "           3       0.92      0.92      0.92      5964\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     22359\n",
      "   macro avg       0.94      0.93      0.93     22359\n",
      "weighted avg       0.94      0.94      0.94     22359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain_matrix,ytrain_matrix):\n",
    "    classifier.fit(xtrain_matrix[train_index],ytrain_matrix[train_index])\n",
    "    ypred=classifier.predict(xtrain_matrix[test_index])\n",
    "    ytestt=ytrain_matrix[test_index]\n",
    "    print(clrp(ytestt,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = LinearSVC(tol=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      4995\n",
      "           1       0.98      0.99      0.98      8947\n",
      "           2       0.96      0.96      0.96      2358\n",
      "           3       0.94      0.94      0.94      6059\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.95      0.95      0.95     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      5029\n",
      "           1       0.98      0.98      0.98      8878\n",
      "           2       0.96      0.95      0.96      2419\n",
      "           3       0.93      0.93      0.93      6033\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.95      0.95      0.95     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      4893\n",
      "           1       0.98      0.98      0.98      8972\n",
      "           2       0.96      0.95      0.96      2442\n",
      "           3       0.93      0.94      0.93      6052\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.95      0.94      0.95     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      4889\n",
      "           1       0.99      0.98      0.99      9120\n",
      "           2       0.96      0.96      0.96      2351\n",
      "           3       0.93      0.93      0.93      5999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.95      0.95      0.95     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      5028\n",
      "           1       0.98      0.98      0.98      8917\n",
      "           2       0.97      0.95      0.96      2450\n",
      "           3       0.93      0.93      0.93      5964\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.95      0.95      0.95     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain_matrix,ytrain_matrix):\n",
    "    classifier2.fit(xtrain_matrix[train_index],ytrain_matrix[train_index])\n",
    "    ypred=classifier2.predict(xtrain_matrix[test_index])\n",
    "    ytestt=ytrain_matrix[test_index]\n",
    "    print(clrp(ytestt,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components = 3000,random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = svd.fit_transform(xtrain_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111795, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      4995\n",
      "           1       0.94      0.98      0.96      8947\n",
      "           2       0.97      0.84      0.90      2358\n",
      "           3       0.92      0.92      0.92      6059\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     22359\n",
      "   macro avg       0.93      0.91      0.92     22359\n",
      "weighted avg       0.93      0.93      0.93     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      5029\n",
      "           1       0.93      0.98      0.96      8878\n",
      "           2       0.97      0.82      0.89      2419\n",
      "           3       0.92      0.93      0.92      6033\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     22359\n",
      "   macro avg       0.93      0.90      0.92     22359\n",
      "weighted avg       0.93      0.93      0.93     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      4893\n",
      "           1       0.94      0.97      0.95      8972\n",
      "           2       0.97      0.85      0.91      2442\n",
      "           3       0.91      0.91      0.91      6052\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     22359\n",
      "   macro avg       0.93      0.91      0.92     22359\n",
      "weighted avg       0.93      0.93      0.92     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      4889\n",
      "           1       0.94      0.98      0.96      9120\n",
      "           2       0.97      0.84      0.90      2351\n",
      "           3       0.92      0.92      0.92      5999\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     22359\n",
      "   macro avg       0.93      0.91      0.92     22359\n",
      "weighted avg       0.93      0.93      0.93     22359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      5028\n",
      "           1       0.93      0.98      0.95      8917\n",
      "           2       0.98      0.82      0.89      2450\n",
      "           3       0.92      0.92      0.92      5964\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     22359\n",
      "   macro avg       0.93      0.90      0.92     22359\n",
      "weighted avg       0.93      0.93      0.93     22359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain,ytrain_matrix):\n",
    "    classifier.fit(x_train[train_index],ytrain_matrix[train_index])\n",
    "    ypred=classifier.predict(x_train[test_index])\n",
    "    ytestt=ytrain_matrix[test_index]\n",
    "    print(clrp(ytestt,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      4995\n",
      "           1       0.98      0.98      0.98      8947\n",
      "           2       0.96      0.94      0.95      2358\n",
      "           3       0.93      0.94      0.93      6059\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.95      0.94      0.94     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      5029\n",
      "           1       0.97      0.98      0.98      8878\n",
      "           2       0.97      0.93      0.95      2419\n",
      "           3       0.93      0.93      0.93      6033\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.95      0.94      0.94     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      4893\n",
      "           1       0.98      0.98      0.98      8972\n",
      "           2       0.95      0.95      0.95      2442\n",
      "           3       0.92      0.94      0.93      6052\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.94      0.94      0.94     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      4889\n",
      "           1       0.98      0.98      0.98      9120\n",
      "           2       0.96      0.94      0.95      2351\n",
      "           3       0.94      0.93      0.93      5999\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.95      0.94      0.94     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      5028\n",
      "           1       0.98      0.98      0.98      8917\n",
      "           2       0.96      0.94      0.95      2450\n",
      "           3       0.93      0.93      0.93      5964\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     22359\n",
      "   macro avg       0.95      0.94      0.94     22359\n",
      "weighted avg       0.95      0.95      0.95     22359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(xtrain,ytrain_matrix):\n",
    "    classifier2.fit(x_train[train_index],ytrain_matrix[train_index])\n",
    "    ypred=classifier2.predict(x_train[test_index])\n",
    "    ytestt=ytrain_matrix[test_index]\n",
    "    print(clrp(ytestt,ypred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
